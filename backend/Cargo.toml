[package]
name = "workbench-server"
version = "0.1.0"
edition = "2021"
authors = ["Workbench Team"]
description = "LLM Chat Application Backend"

[[bin]]
name = "workbench-server"
path = "src/main.rs"

[lib]
name = "workbench_server"
path = "src/lib.rs"

[dependencies]
# Web framework
axum = "0.7"
tokio = { version = "1.0", features = ["full"] }
tower = { version = "0.4", features = ["util", "timeout", "limit"] }
tower-http = { version = "0.5", features = ["cors", "trace"] }

# OpenAI integration
async-openai = "0.20"

# Database
sqlx = { version = "0.8", features = ["runtime-tokio-rustls", "postgres", "uuid", "chrono", "json", "migrate"] }

# UUID support
uuid = { version = "1.0", features = ["serde", "v4"] }

# Time handling
chrono = { version = "0.4", features = ["serde"] }

# Validation
validator = { version = "0.18", features = ["derive"] }

# Password hashing
argon2 = { version = "0.5", features = ["std"] }

# Async trait support
async-trait = "0.1"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Error handling
anyhow = "1.0"
thiserror = "1.0"

# Environment variables
dotenvy = "0.15"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# HTTP client for OpenAI
reqwest = { version = "0.12", features = ["json", "stream"] }

# Async streams
futures = "0.3"
tokio-stream = "0.1"

# Configuration
config = "0.14"

[dev-dependencies]
tokio-test = "0.4"
